from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from typing import Dict, List
import json
from config.settings import LLM_MODEL, LLM_TEMPERATURE, OPENAI_API_KEY
from tools.evaluation_tools import EvaluationTools
from prompts.improvement import IMPROVEMENT_SUGGESTION_PROMPT, COMPARISON_PROMPT

class ImprovementAdvisor:
    """ê°œì„ ì•ˆ ì œì•ˆ ì—ì´ì „íŠ¸ - ìœ¤ë¦¬ì„± ê°•í™” ìœ„í•œ êµ¬ì²´ì  ê°œì„  ë°©í–¥ ì œì•ˆ"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model=LLM_MODEL,
            temperature=LLM_TEMPERATURE,
            openai_api_key=OPENAI_API_KEY
        )
        self.eval_tools = EvaluationTools()
    
    def suggest_improvements(
        self,
        service_name: str,
        risk_assessment: Dict
    ) -> List[Dict]:
        """ë¦¬ìŠ¤í¬ í‰ê°€ ê¸°ë°˜ ê°œì„ ì•ˆ ì œì•ˆ"""
        
        print(f"\n{'='*60}")
        print(f"ğŸ’¡ [{service_name}] ê°œì„ ì•ˆ ì œì•ˆ ìƒì„±")
        print(f"{'='*60}\n")
        
        # 1. ê°œì„  ìš°ì„ ìˆœìœ„ íŒŒì•…
        priority_areas = self.eval_tools.prioritize_improvements(risk_assessment)
        
        if not priority_areas:
            print(f"  âœ… ì¦‰ê°ì ì¸ ê°œì„ ì´ í•„ìš”í•œ ì˜ì—­ ì—†ìŒ (ëª¨ë“  ì ìˆ˜ 3.5 ì´ìƒ)")
            return []
        
        print(f"  ğŸ“Œ ê°œì„  í•„ìš” ì˜ì—­: {len(priority_areas)}ê°œ")
        for area in priority_areas:
            print(f"     - {area['dimension']}: {area['current_score']}/5 (ìš°ì„ ìˆœìœ„: {area['priority']})")
        
        # 2. LLMìœ¼ë¡œ ê°œì„ ì•ˆ ìƒì„±
        print(f"\n  ğŸ¤– êµ¬ì²´ì  ê°œì„ ì•ˆ ìƒì„± ì¤‘...")
        improvements = self._generate_improvements(
            service_name=service_name,
            risk_assessment=risk_assessment,
            priority_areas=priority_areas
        )
        
        if improvements:
            print(f"  âœ… ê°œì„ ì•ˆ ìƒì„± ì™„ë£Œ! ({len(improvements)}ê°œ ì˜ì—­)")
        
        return improvements
    
    def _generate_improvements(
        self,
        service_name: str,
        risk_assessment: Dict,
        priority_areas: List[Dict]
    ) -> List[Dict]:
        """LLMì„ í†µí•œ ê°œì„ ì•ˆ ìƒì„±"""
        
        prompt = IMPROVEMENT_SUGGESTION_PROMPT.format(
            service_name=service_name,
            risk_assessment=json.dumps(risk_assessment, ensure_ascii=False, indent=2),
            priority_areas=json.dumps(priority_areas, ensure_ascii=False, indent=2)
        )
        
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ AI ìœ¤ë¦¬ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‹¤í–‰ ê°€ëŠ¥í•˜ê³  êµ¬ì²´ì ì´ë©° ì¸¡ì • ê°€ëŠ¥í•œ ê°œì„ ì•ˆì„ ì œì‹œí•˜ì„¸ìš”."),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = self.llm.invoke(messages)
            
            content = response.content.strip()
            if content.startswith("```json"):
                content = content[7:]
            if content.startswith("```"):
                content = content[3:]
            if content.endswith("```"):
                content = content[:-3]
            
            improvements = json.loads(content.strip())
            return improvements
        
        except Exception as e:
            print(f"  âš ï¸  ê°œì„ ì•ˆ ìƒì„± ì˜¤ë¥˜: {e}")
            return []
    
    def compare_services(
        self,
        services_data: Dict[str, Dict]
    ) -> str:
        """ì—¬ëŸ¬ ì„œë¹„ìŠ¤ ë¹„êµ ë¶„ì„"""
        
        if len(services_data) < 2:
            return ""
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ì„œë¹„ìŠ¤ ë¹„êµ ë¶„ì„")
        print(f"{'='*60}\n")
        
        services_list = ", ".join(services_data.keys())
        
        # ë¦¬ìŠ¤í¬ í‰ê°€ ê²°ê³¼ ì¶”ì¶œ
        all_assessments = {
            name: data['risk_assessment']
            for name, data in services_data.items()
        }
        
        # í‰ê°€ ë„êµ¬ë¡œ ë¹„êµ
        comparison_data = self.eval_tools.compare_services(all_assessments)
        
        print(f"  ğŸ“‹ ì¢…í•© ìˆœìœ„:")
        for i, rank in enumerate(comparison_data['service_rankings'], 1):
            print(f"     {i}ìœ„: {rank['service']} - {rank['overall_score']}/5 ({rank['risk_level']})")
        
        # LLM ë¹„êµ ë¶„ì„
        prompt = COMPARISON_PROMPT.format(
            services_list=services_list,
            all_assessments=json.dumps(all_assessments, ensure_ascii=False, indent=2)
        )
        
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ AI ì„œë¹„ìŠ¤ ë¹„êµ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê°ê´€ì ì´ê³  ê· í˜•ì¡íŒ í†µì°°ì„ ì œê³µí•˜ì„¸ìš”."),
            HumanMessage(content=prompt)
        ]
        
        response = self.llm.invoke(messages)
        
        print(f"  âœ… ë¹„êµ ë¶„ì„ ì™„ë£Œ\n")
        
        return response.content

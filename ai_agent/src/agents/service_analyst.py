from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from src.graph.state import AIEthicsState
from src.prompts.analyst_prompt import get_analyst_prompt
import json
import os


class ServiceAnalystAgent:
    """ì„œë¹„ìŠ¤ ë¶„ì„ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.3,
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
    
    def analyze(self, state: AIEthicsState) -> AIEthicsState:
        """ì„œë¹„ìŠ¤ ë¶„ì„ ìˆ˜í–‰"""
        print("\nðŸ” ì„œë¹„ìŠ¤ ë¶„ì„ ì¤‘...")
        
        prompt = get_analyst_prompt(state)
        
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ AI ì„œë¹„ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]
        
        response = self.llm.invoke(messages)
        
        try:
            # JSON íŒŒì‹±
            analysis = json.loads(response.content)
        except json.JSONDecodeError:
            # JSONì´ ì•„ë‹Œ ê²½ìš° í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”
            analysis = {
                "ê°œìš”": response.content,
                "íŒŒì‹±ë¨": False
            }
        
        state['service_analysis'] = analysis
        print("âœ“ ì„œë¹„ìŠ¤ ë¶„ì„ ì™„ë£Œ")
        
        return state


def service_analyst_node(state: AIEthicsState) -> AIEthicsState:
    """LangGraph ë…¸ë“œ í•¨ìˆ˜"""
    agent = ServiceAnalystAgent()
    return agent.analyze(state)
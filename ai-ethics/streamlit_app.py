import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime
import json
import os
import sys
from typing import Dict, List
import pandas as pd

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ì‹¤ì œ ì‹œìŠ¤í…œ import
try:
    from app import AIEthicsAssessmentSystem
    SYSTEM_AVAILABLE = True
except ImportError:
    try:
        from main import AIEthicsAssessmentSystem
        SYSTEM_AVAILABLE = True
    except ImportError:
        SYSTEM_AVAILABLE = False

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ìœ¤ë¦¬ì„± ë¦¬ìŠ¤í¬ ì§„ë‹¨",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main-header { 
        font-size: 2.5rem; 
        font-weight: bold; 
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center; 
        margin-bottom: 2rem; 
    }
    .metric-card { 
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
        padding: 20px; 
        border-radius: 15px; 
        color: white; 
        text-align: center; 
        margin: 10px 0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .risk-high { 
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); 
    }
    .risk-medium { 
        background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%); 
        color: #333;
    }
    .risk-low { 
        background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%); 
        color: #333;
    }
    .detail-card { 
        border-left: 4px solid #667eea; 
        padding: 20px; 
        margin: 15px 0; 
        background: #f8f9fa; 
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .evidence-item {
        background: #e3f2fd;
        padding: 10px;
        margin: 5px 0;
        border-radius: 5px;
        border-left: 3px solid #2196f3;
    }
    .risk-item {
        background: #ffebee;
        padding: 10px;
        margin: 5px 0;
        border-radius: 5px;
        border-left: 3px solid #f44336;
    }
    .strength-item {
        background: #e8f5e9;
        padding: 10px;
        margin: 5px 0;
        border-radius: 5px;
        border-left: 3px solid #4caf50;
    }
    .guideline-box {
        background: white;
        padding: 15px;
        margin: 10px 0;
        border-radius: 8px;
        border: 2px solid #e0e0e0;
    }
    .progress-step {
        padding: 12px;
        margin: 8px 0;
        border-radius: 8px;
        background: #e3f2fd;
        border-left: 4px solid #2196f3;
        font-size: 14px;
    }
    .progress-step.complete {
        background: #e8f5e9;
        border-left-color: #4caf50;
    }
    .progress-step.active {
        background: #fff3e0;
        border-left-color: #ff9800;
        animation: pulse 2s infinite;
    }
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.7; }
    }
    .stButton>button { 
        width: 100%; 
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
        color: white; 
        font-weight: bold;
        border: none;
        border-radius: 8px;
        padding: 10px;
        transition: all 0.3s;
    }
    .stButton>button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
    }
    .improvement-detail {
        background: #f0fff4;
        padding: 15px;
        margin: 10px 0;
        border-radius: 8px;
        border: 2px solid #28a745;
    }
</style>
""", unsafe_allow_html=True)


class EthicsDashboard:
    """ìœ¤ë¦¬ì„± í‰ê°€ ëŒ€ì‹œë³´ë“œ"""
    
    def __init__(self):
        self.dimensions = {
            "fairness": "ê³µì •ì„± ë° í¸í–¥ì„±",
            "privacy": "í”„ë¼ì´ë²„ì‹œ ë³´í˜¸",
            "transparency": "íˆ¬ëª…ì„± ë° ì„¤ëª…ê°€ëŠ¥ì„±",
            "accountability": "ì±…ì„ì„± ë° ê±°ë²„ë„ŒìŠ¤",
            "safety": "ì•ˆì „ì„± ë° ë³´ì•ˆ"
        }
        
        self.dimensions_en = {
            "fairness": "Fairness & Bias",
            "privacy": "Privacy Protection",
            "transparency": "Transparency & Explainability",
            "accountability": "Accountability & Governance",
            "safety": "Safety & Security"
        }
        
        self.initialize_session_state()
        
        # ì‹¤ì œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if SYSTEM_AVAILABLE and 'system' not in st.session_state:
            with st.spinner("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘..." if self.is_korean() else "Initializing system..."):
                st.session_state.system = AIEthicsAssessmentSystem()
    
    def initialize_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'analysis_done' not in st.session_state:
            st.session_state.analysis_done = False
        if 'results' not in st.session_state:
            st.session_state.results = None
        if 'progress_logs' not in st.session_state:
            st.session_state.progress_logs = []
        if 'language' not in st.session_state:
            st.session_state.language = 'ko'
    
    def is_korean(self):
        """í˜„ì¬ ì–¸ì–´ê°€ í•œêµ­ì–´ì¸ì§€ í™•ì¸"""
        return st.session_state.language == 'ko'
    
    def t(self, key: str) -> str:
        """ë²ˆì—­ í…ìŠ¤íŠ¸ ë°˜í™˜"""
        texts = {
            'ko': {
                'main_title': 'âš–ï¸ AI ìœ¤ë¦¬ì„± ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì‹œìŠ¤í…œ',
                'settings': 'ğŸ”§ ì„¤ì •',
                'language_setting': 'ğŸŒ ì–¸ì–´ ì„¤ì •',
                'analysis_services': 'ğŸ“‹ ë¶„ì„ ì„œë¹„ìŠ¤',
                'select_services': 'ë¶„ì„í•  AI ì„œë¹„ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš” (ìµœëŒ€ 3ê°œ)',
                'evaluation_settings': 'âš™ï¸ í‰ê°€ ì„¤ì •',
                'applied_guidelines': 'ì ìš© ê°€ì´ë“œë¼ì¸',
                'start_analysis': 'ğŸš€ ë¶„ì„ ì‹œì‘',
                'previous_reports': 'ğŸ“‚ ì´ì „ ë³´ê³ ì„œ',
                'load_report': 'ë³´ê³ ì„œ ë¶ˆëŸ¬ì˜¤ê¸°',
                'evaluation_dimensions': 'â„¹ï¸ í‰ê°€ ì°¨ì›',
                'welcome_title': 'í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‘‹',
                'welcome_desc': '''AI ì„œë¹„ìŠ¤ì˜ ìœ¤ë¦¬ì  ë¦¬ìŠ¤í¬ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ì§„ë‹¨í•˜ê³  ê°œì„  ë°©í–¥ì„ ì œì‹œí•©ë‹ˆë‹¤.

âœ¨ **ì£¼ìš” ê¸°ëŠ¥**
- âš–ï¸ 5ê°œ ì°¨ì› ì‹¬ì¸µ ìœ¤ë¦¬ í‰ê°€
- ğŸ“Š ì‹¤ì‹œê°„ ë¶„ì„ ì§„í–‰ ëª¨ë‹ˆí„°ë§
- ğŸ’¡ êµ¬ì²´ì ì¸ ê°œì„  ê¶Œê³ ì•ˆ
- ğŸ“ˆ ê°€ì´ë“œë¼ì¸ë³„ ì¤€ìˆ˜ í˜„í™©
- ğŸ” ì„œë¹„ìŠ¤ ê°„ ë¹„êµ ë¶„ì„

ğŸ‘ˆ **ì‹œì‘í•˜ê¸°**: ì™¼ìª½ì—ì„œ ë¶„ì„í•  ì„œë¹„ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”!''',
                'analysis_in_progress': 'ğŸ”„ ë¶„ì„ ì§„í–‰ ì¤‘...',
                'analysis_complete': 'âœ… ë¶„ì„ ì™„ë£Œ!',
                'tab_overview': 'ğŸ“Š ì¢…í•© ëŒ€ì‹œë³´ë“œ',
                'tab_detailed': 'ğŸ“ˆ ìƒì„¸ í‰ê°€',
                'tab_improvement': 'ğŸ’¡ ê°œì„  ê¶Œê³ ì•ˆ',
                'tab_comparison': 'ğŸ” ë¹„êµ ë¶„ì„',
                'tab_report': 'ğŸ“„ ìµœì¢… ë³´ê³ ì„œ',
                'new_analysis': 'ğŸ”„ ìƒˆë¡œìš´ ë¶„ì„',
                'save_results': 'ğŸ’¾ ê²°ê³¼ ì €ì¥',
                'download_report': 'ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ',
                'analyzed_services': 'ë¶„ì„ ì„œë¹„ìŠ¤',
                'avg_score': 'í‰ê·  ì ìˆ˜',
                'overall_risk': 'ì¢…í•© ë¦¬ìŠ¤í¬',
                'improvements': 'ê°œì„  ê¶Œê³ ',
                'low': 'ë‚®ìŒ',
                'medium': 'ì¤‘ê°„',
                'high': 'ë†’ìŒ',
                'dimension_evaluation': 'ì°¨ì›ë³„ í‰ê°€',
                'score_comparison': 'ì¢…í•© ì ìˆ˜ ë¹„êµ',
                'service': 'ì„œë¹„ìŠ¤',
                'overall_score': 'ì¢…í•©ì ìˆ˜',
                'detailed_evaluation': 'ìƒì„¸ í‰ê°€',
                'select_service': 'ì„œë¹„ìŠ¤ ì„ íƒ',
                'risk': 'ë¦¬ìŠ¤í¬',
                'overall_assessment': 'ì¢…í•© í‰ê°€',
                'excellent': 'ìš°ìˆ˜í•œ ìœ¤ë¦¬ì„± ìˆ˜ì¤€ì„ ë³´ì…ë‹ˆë‹¤',
                'good': 'ì–‘í˜¸í•˜ë‚˜ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤',
                'needs_improvement': 'ì¤‘ëŒ€í•œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤',
                'dimension_details': 'ì°¨ì›ë³„ ìƒì„¸ í‰ê°€',
                'score': 'ì ìˆ˜',
                'guideline_compliance': 'ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜',
                'evaluation_desc': 'í‰ê°€ ì„¤ëª…',
                'key_evidence': 'ì£¼ìš” ì¦ê±°',
                'no_evidence': 'ì¦ê±° ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤',
                'identified_risks': 'ë°œê²¬ëœ ë¦¬ìŠ¤í¬',
                'strengths': 'ê°•ì ',
                'improvement_recommendations': 'ê°œì„  ê¶Œê³ ì•ˆ',
                'all_excellent': 'ğŸ‰ í˜„ì¬ ëª¨ë“  ì˜ì—­ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤!',
                'priority_filter': 'ìš°ì„ ìˆœìœ„ í•„í„°',
                'all': 'ì „ì²´',
                'priority_high': 'ìƒ',
                'priority_medium': 'ì¤‘',
                'priority_low': 'í•˜',
                'current_score': 'í˜„ì¬ ì ìˆ˜',
                'target_score': 'ëª©í‘œ ì ìˆ˜',
                'improvement_goal': 'ê°œì„  ëª©í‘œ',
                'current_issues': 'í˜„ì¬ ë¬¸ì œì ',
                'recommended_actions': 'ê¶Œì¥ ê°œì„  ì¡°ì¹˜',
                'implementation_steps': 'êµ¬í˜„ ë‹¨ê³„',
                'expected_impact': 'ê¸°ëŒ€ íš¨ê³¼',
                'timeline': 'ì†Œìš” ê¸°ê°„',
                'comparison_analysis': 'ë¹„êµ ë¶„ì„',
                'comparison_note': 'ë¹„êµ ë¶„ì„ì€ 2ê°œ ì´ìƒì˜ ì„œë¹„ìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤',
                'dimension_comparison': 'ì°¨ì›ë³„ ì ìˆ˜ ë¹„êµ',
                'dimension': 'ì°¨ì›',
                'score_heatmap': 'ì ìˆ˜ íˆíŠ¸ë§µ',
                'final_report': 'ìµœì¢… ë³´ê³ ì„œ',
                'report_download': 'ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ',
                'report_saved': 'ë³´ê³ ì„œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤',
                'no_saved_reports': 'ì €ì¥ëœ ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤',
                'select_report': 'ë¶ˆëŸ¬ì˜¬ ë³´ê³ ì„œ ì„ íƒ',
                'load': 'ë¶ˆëŸ¬ì˜¤ê¸°',
                'report_loaded': 'ë³´ê³ ì„œë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤',
            },
            'en': {
                'main_title': 'âš–ï¸ AI Ethics Risk Assessment System',
                'settings': 'ğŸ”§ Settings',
                'language_setting': 'ğŸŒ Language',
                'analysis_services': 'ğŸ“‹ Analysis Services',
                'select_services': 'Select AI services to analyze (max 3)',
                'evaluation_settings': 'âš™ï¸ Evaluation Settings',
                'applied_guidelines': 'Applied Guidelines',
                'start_analysis': 'ğŸš€ Start Analysis',
                'previous_reports': 'ğŸ“‚ Previous Reports',
                'load_report': 'Load Report',
                'evaluation_dimensions': 'â„¹ï¸ Evaluation Dimensions',
                'welcome_title': 'Welcome! ğŸ‘‹',
                'welcome_desc': '''Comprehensively diagnose ethical risks of AI services and provide improvement directions.

âœ¨ **Key Features**
- âš–ï¸ In-depth ethics evaluation across 5 dimensions
- ğŸ“Š Real-time analysis progress monitoring
- ğŸ’¡ Specific improvement recommendations
- ğŸ“ˆ Guideline compliance status
- ğŸ” Service comparison analysis

ğŸ‘ˆ **Get Started**: Select services to analyze from the left!''',
                'analysis_in_progress': 'ğŸ”„ Analysis in Progress...',
                'analysis_complete': 'âœ… Analysis Complete!',
                'tab_overview': 'ğŸ“Š Overview',
                'tab_detailed': 'ğŸ“ˆ Detailed Assessment',
                'tab_improvement': 'ğŸ’¡ Improvements',
                'tab_comparison': 'ğŸ” Comparison',
                'tab_report': 'ğŸ“„ Report',
                'new_analysis': 'ğŸ”„ New Analysis',
                'save_results': 'ğŸ’¾ Save Results',
                'download_report': 'ğŸ“¥ Download Report',
                'analyzed_services': 'Services',
                'avg_score': 'Avg Score',
                'overall_risk': 'Risk Level',
                'improvements': 'Improvements',
                'low': 'Low',
                'medium': 'Medium',
                'high': 'High',
                'dimension_evaluation': 'Dimension Evaluation',
                'score_comparison': 'Score Comparison',
                'service': 'Service',
                'overall_score': 'Overall Score',
                'detailed_evaluation': 'Detailed Assessment',
                'select_service': 'Select Service',
                'risk': 'Risk',
                'overall_assessment': 'Overall Assessment',
                'excellent': 'shows excellent ethics level',
                'good': 'is good but needs improvement',
                'needs_improvement': 'needs significant improvement',
                'dimension_details': 'Dimension Details',
                'score': 'Score',
                'guideline_compliance': 'Guideline Compliance',
                'evaluation_desc': 'Evaluation Description',
                'key_evidence': 'Key Evidence',
                'no_evidence': 'No evidence information available',
                'identified_risks': 'Identified Risks',
                'strengths': 'Strengths',
                'improvement_recommendations': 'Improvement Recommendations',
                'all_excellent': 'ğŸ‰ All areas are currently excellent!',
                'priority_filter': 'Priority Filter',
                'all': 'All',
                'priority_high': 'High',
                'priority_medium': 'Medium',
                'priority_low': 'Low',
                'current_score': 'Current',
                'target_score': 'Target',
                'improvement_goal': 'Goal',
                'current_issues': 'Current Issues',
                'recommended_actions': 'Recommended Actions',
                'implementation_steps': 'Implementation Steps',
                'expected_impact': 'Expected Impact',
                'timeline': 'Timeline',
                'comparison_analysis': 'Comparison Analysis',
                'comparison_note': 'Comparison requires 2 or more services',
                'dimension_comparison': 'Dimension Score Comparison',
                'dimension': 'Dimension',
                'score_heatmap': 'Score Heatmap',
                'final_report': 'Final Report',
                'report_download': 'Download Report',
                'report_saved': 'Report has been saved',
                'no_saved_reports': 'No saved reports',
                'select_report': 'Select report to load',
                'load': 'Load',
                'report_loaded': 'Report loaded successfully',
            }
        }
        
        lang = 'ko' if self.is_korean() else 'en'
        return texts.get(lang, texts['ko']).get(key, key)
    
    def get_dimension_name(self, key: str) -> str:
        """ì°¨ì› ì´ë¦„ ë°˜í™˜ (ì–¸ì–´ë³„)"""
        if self.is_korean():
            return self.dimensions.get(key, key)
        else:
            return self.dimensions_en.get(key, key)
    
    def run(self):
        """ëŒ€ì‹œë³´ë“œ ì‹¤í–‰"""
        if not SYSTEM_AVAILABLE:
            warning_msg = "âš ï¸ AIEthicsAssessmentSystemì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤." if self.is_korean() else "âš ï¸ AIEthicsAssessmentSystem unavailable. Running in demo mode."
            st.warning(warning_msg)
        
        st.markdown(f'<div class="main-header">{self.t("main_title")}</div>', unsafe_allow_html=True)
        
        # ì‚¬ì´ë“œë°”
        with st.sidebar:
            st.header(self.t('settings'))
            self.render_sidebar()
        
        # ë©”ì¸ ì»¨í…ì¸ 
        if not st.session_state.analysis_done:
            self.render_welcome_page()
        else:
            self.render_results_page()
    
    def render_sidebar(self):
        """ì‚¬ì´ë“œë°” ë Œë”ë§"""
        # ì–¸ì–´ ì„ íƒ
        st.markdown(f"### {self.t('language_setting')}")
        lang_options = ['í•œêµ­ì–´', 'English']
        current_idx = 0 if self.is_korean() else 1
        
        selected_lang = st.radio(
            "Language / ì–¸ì–´",
            options=lang_options,
            index=current_idx,
            horizontal=True,
            label_visibility="collapsed"
        )
        
        new_lang = 'ko' if selected_lang == 'í•œêµ­ì–´' else 'en'
        if new_lang != st.session_state.language:
            st.session_state.language = new_lang
            st.rerun()
        
        st.markdown("---")
        
        # ì„œë¹„ìŠ¤ ì„ íƒ
        st.markdown(f"### {self.t('analysis_services')}")
        services = st.multiselect(
            self.t('select_services'),
            ["ChatGPT", "Claude", "Google Gemini", "Copilot", "Midjourney", "DALL-E"],
            max_selections=3
        )
        
        # í‰ê°€ ì„¤ì •
        st.markdown(f"### {self.t('evaluation_settings')}")
        guideline_text = f"**{self.t('applied_guidelines')}**\n- EU AI Act\n- UNESCO AI Ethics\n- OECD AI Principles"
        st.info(guideline_text)
        
        if st.button(self.t('start_analysis'), disabled=len(services)==0):
            self.start_analysis(services)
        
        st.markdown("---")
        
        # ì´ì „ ë³´ê³ ì„œ
        st.markdown(f"### {self.t('previous_reports')}")
        if st.button(self.t('load_report')):
            self.load_previous_report()
        
        st.markdown("---")
        
        # í‰ê°€ ì°¨ì›
        st.markdown(f"### {self.t('evaluation_dimensions')}")
        dim_emojis = ["ğŸ¯", "ğŸ”’", "ğŸ”", "âš–ï¸", "ğŸ›¡ï¸"]
        for emoji, dim_key in zip(dim_emojis, self.dimensions.keys()):
            st.markdown(f"{emoji} {self.get_dimension_name(dim_key)}")
    
    def render_welcome_page(self):
        """í™˜ì˜ í˜ì´ì§€"""
        col1, col2, col3 = st.columns([1,2,1])
        with col2:
            st.markdown(f"## {self.t('welcome_title')}")
            st.markdown(self.t('welcome_desc'))
    
    def start_analysis(self, services: List[str]):
        """ì‹¤ì œ ì‹œìŠ¤í…œ ë¶„ì„ ì‹¤í–‰"""
        st.session_state.progress_logs = []
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ ì˜ì—­
        progress_container = st.container()
        
        with progress_container:
            st.markdown(f"### {self.t('analysis_in_progress')}")
            progress_area = st.empty()
            status_text = st.empty()
            progress_bar = st.progress(0)
        
        try:
            if SYSTEM_AVAILABLE:
                # ì‹¤ì œ ì‹œìŠ¤í…œ ì‹¤í–‰
                msg = "ì‹¤ì œ AI ìœ¤ë¦¬ì„± ë¶„ì„ ì‹œìŠ¤í…œì„ ì‹¤í–‰í•©ë‹ˆë‹¤..." if self.is_korean() else "Running real AI ethics analysis system..."
                status_text.info(msg)
                
                # ì„ì‹œ ì¶œë ¥ ë””ë ‰í† ë¦¬
                output_dir = "outputs/streamlit_temp"
                os.makedirs(output_dir, exist_ok=True)
                
                # ë¶„ì„ ì‹¤í–‰
                report = st.session_state.system.analyze_services(
                    service_names=services,
                    output_dir=output_dir
                )
                
                # ê²°ê³¼ ë¡œë“œ
                latest_files = sorted([f for f in os.listdir(output_dir) if f.endswith('_data.json')])
                if latest_files:
                    with open(os.path.join(output_dir, latest_files[-1]), 'r', encoding='utf-8') as f:
                        detailed_data = json.load(f)
                    
                    st.session_state.results = {
                        'services': services,
                        'report': report,
                        'detailed_data': detailed_data,
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    progress_bar.progress(1.0)
                    status_text.success(self.t('analysis_complete'))
                    st.session_state.analysis_done = True
                    st.rerun()
            else:
                # ë°ëª¨ ëª¨ë“œ
                demo_msg = "âš ï¸ ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤." if self.is_korean() else "âš ï¸ Running in demo mode."
                st.warning(demo_msg)
                self.run_demo_analysis(services, progress_area, progress_bar, status_text)
                
        except Exception as e:
            error_msg = f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}" if self.is_korean() else f"âŒ Error during analysis: {e}"
            st.error(error_msg)
            import traceback
            with st.expander("Error details" if not self.is_korean() else "ì˜¤ë¥˜ ìƒì„¸"):
                st.code(traceback.format_exc())
    
    def run_demo_analysis(self, services, progress_area, progress_bar, status_text):
        """ë°ëª¨ ë¶„ì„"""
        import time
        
        if self.is_korean():
            steps = [
                "ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...",
                f"ì„œë¹„ìŠ¤ ë¶„ì„ ì‹œì‘: {', '.join(services)}",
                "1ë‹¨ê³„: ì„œë¹„ìŠ¤ ì •ë³´ ìˆ˜ì§‘ ë° ë¶„ì„ ì¤‘...",
                "2ë‹¨ê³„: ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ ìƒì„¸ í‰ê°€ ì¤‘...",
                "3ë‹¨ê³„: ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜ ì—¬ë¶€ ê²€ì¦ ì¤‘...",
                "4ë‹¨ê³„: ê°œì„ ì•ˆ ìƒì„± ì¤‘...",
                "5ë‹¨ê³„: ë¹„êµ ë¶„ì„ ì¤‘..." if len(services) > 1 else "5ë‹¨ê³„: ê±´ë„ˆë›°ê¸°...",
                "6ë‹¨ê³„: ìµœì¢… ë³´ê³ ì„œ ì‘ì„± ì¤‘...",
            ]
        else:
            steps = [
                "Initializing system...",
                f"Starting analysis: {', '.join(services)}",
                "Step 1: Collecting service information...",
                "Step 2: Assessing ethical risks...",
                "Step 3: Verifying guideline compliance...",
                "Step 4: Generating improvements...",
                "Step 5: Comparing services..." if len(services) > 1 else "Step 5: Skipping...",
                "Step 6: Writing final report...",
            ]
        
        for idx, step in enumerate(steps):
            st.session_state.progress_logs.append({"step": step, "status": "active"})
            
            with progress_area:
                for i, log in enumerate(st.session_state.progress_logs):
                    if i == len(st.session_state.progress_logs) - 1:
                        st.markdown(f'<div class="progress-step active">â³ {log["step"]}</div>', 
                                   unsafe_allow_html=True)
                    else:
                        st.markdown(f'<div class="progress-step complete">âœ… {log["step"]}</div>', 
                                   unsafe_allow_html=True)
            
            progress_bar.progress((idx + 1) / len(steps))
            time.sleep(1)
            st.session_state.progress_logs[-1]["status"] = "complete"
        
        # ìƒì„¸í•œ ìƒ˜í”Œ ê²°ê³¼ ìƒì„±
        detailed_data = self.generate_detailed_sample_data(services)
        
        st.session_state.results = {
            'services': services,
            'report': self.generate_detailed_report(services, detailed_data),
            'detailed_data': detailed_data,
            'timestamp': datetime.now().isoformat()
        }
        
        status_text.success(self.t('analysis_complete'))
        time.sleep(1)
        st.session_state.analysis_done = True
        st.rerun()
    
    def generate_detailed_sample_data(self, services: List[str]) -> Dict:
        """ìƒì„¸í•œ ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
        import random
        
        if self.is_korean():
            guideline_requirements = {
                "EU AI Act": {
                    "fairness": "ê³ ìœ„í—˜ AI ì‹œìŠ¤í…œì˜ ê²½ìš° í¸í–¥ì„± í…ŒìŠ¤íŠ¸ ë° ì™„í™” ì¡°ì¹˜ í•„ìˆ˜",
                    "privacy": "GDPR ì¤€ìˆ˜ ë° ë°ì´í„° ìµœì†Œí™” ì›ì¹™ ì ìš©",
                    "transparency": "AI ì‹œìŠ¤í…œ ì‘ë™ ë°©ì‹ì— ëŒ€í•œ ëª…í™•í•œ ì„¤ëª… ì œê³µ",
                    "accountability": "ì±…ì„ì ì§€ì • ë° ì‚¬ê³  ë³´ê³  ì²´ê³„ êµ¬ì¶•",
                    "safety": "ìœ„í—˜ ê´€ë¦¬ ì‹œìŠ¤í…œ ë° ì‚¬ì „ ì í•©ì„± í‰ê°€ ìˆ˜í–‰"
                },
                "UNESCO AI Ethics": {
                    "fairness": "ë‹¤ì–‘ì„± ì¡´ì¤‘ ë° ì°¨ë³„ ë°©ì§€",
                    "privacy": "ê°œì¸ì •ë³´ ìê¸°ê²°ì •ê¶Œ ë³´ì¥",
                    "transparency": "ì•Œê³ ë¦¬ì¦˜ì˜ ì´í•´ê°€ëŠ¥ì„± í™•ë³´",
                    "accountability": "ì¸ê°„ ê°ë… ë° ê°œì… ê°€ëŠ¥ì„± í™•ë³´",
                    "safety": "ì¸ê°„ ë³µì§€ ë° ì•ˆì „ ìš°ì„ "
                },
                "OECD AI Principles": {
                    "fairness": "í¬ìš©ì  ì„±ì¥ ë° ì§€ì†ê°€ëŠ¥í•œ ë°œì „",
                    "privacy": "ì¸ê¶Œê³¼ ë¯¼ì£¼ì  ê°€ì¹˜ ì¡´ì¤‘",
                    "transparency": "AI ì‹œìŠ¤í…œ íˆ¬ëª…ì„± ë° ì±…ì„ìˆëŠ” ê³µê°œ",
                    "accountability": "ê²¬ê³ í•˜ê³  ì•ˆì „í•œ AI",
                    "safety": "ìœ„í—˜ ê¸°ë°˜ ì ‘ê·¼ ë° ì§€ì†ì  ëª¨ë‹ˆí„°ë§"
                }
            }
        else:
            guideline_requirements = {
                "EU AI Act": {
                    "fairness": "Bias testing and mitigation required for high-risk AI systems",
                    "privacy": "GDPR compliance and data minimization principles",
                    "transparency": "Clear explanation of AI system operation",
                    "accountability": "Designated responsible person and incident reporting system",
                    "safety": "Risk management system and pre-conformity assessment"
                },
                "UNESCO AI Ethics": {
                    "fairness": "Respect for diversity and prevention of discrimination",
                    "privacy": "Guarantee of personal information self-determination",
                    "transparency": "Ensuring algorithm understandability",
                    "accountability": "Human oversight and intervention capability",
                    "safety": "Priority on human welfare and safety"
                },
                "OECD AI Principles": {
                    "fairness": "Inclusive growth and sustainable development",
                    "privacy": "Respect for human rights and democratic values",
                    "transparency": "AI system transparency and responsible disclosure",
                    "accountability": "Robust and secure AI",
                    "safety": "Risk-based approach and continuous monitoring"
                }
            }
        
        sample_data = {
            'service_analyses': {},
            'risk_assessments': {},
            'improvement_suggestions': {},
            'comparison_analysis': self.generate_comparison_text(services)
        }
        
        for svc in services:
            if self.is_korean():
                service_desc = f"{svc}ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ê¸°ë°˜ AI ì„œë¹„ìŠ¤ë¡œ, ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ìƒì„± ë° ëŒ€í™” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤."
                features = ["í…ìŠ¤íŠ¸ ìƒì„±", "ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤", "ë‹¤êµ­ì–´ ì§€ì›", "ì»¨í…ìŠ¤íŠ¸ ì´í•´"]
                target = "ì¼ë°˜ ì‚¬ìš©ì, ê¸°ì—…, ê°œë°œì"
                use_cases = ["ì½˜í…ì¸  ì‘ì„±", "ê³ ê° ì„œë¹„ìŠ¤", "êµìœ¡", "ì—°êµ¬ ì§€ì›"]
            else:
                service_desc = f"{svc} is a large language model-based AI service providing various text generation and conversational capabilities."
                features = ["Text generation", "Conversational interface", "Multilingual support", "Context understanding"]
                target = "General users, Enterprises, Developers"
                use_cases = ["Content creation", "Customer service", "Education", "Research support"]
            
            sample_data['service_analyses'][svc] = {
                "service_overview": {
                    "description": service_desc,
                    "main_features": features,
                    "target_users": target,
                    "use_cases": use_cases
                }
            }
            
            scores = {}
            dimension_details = {}
            
            for dim_key in self.dimensions.keys():
                dim_name = self.get_dimension_name(dim_key)
                score = round(random.uniform(2.8, 4.6), 1)
                
                if score >= 4.0:
                    risk_level = self.t('low')
                    description = f"{dim_name} ì˜ì—­ì—ì„œ ìš°ìˆ˜í•œ ìˆ˜ì¤€ì„ ë³´ì…ë‹ˆë‹¤." if self.is_korean() else f"Shows excellent level in {dim_name}."
                    risks = []
                    strengths = [f"ëª…í™•í•œ {dim_name} ì •ì±… ìˆ˜ë¦½", "ì •ê¸°ì ì¸ ëª¨ë‹ˆí„°ë§ ë° í‰ê°€"] if self.is_korean() else [f"Clear {dim_name} policy", "Regular monitoring"]
                    evidence = [f"ê³µê°œëœ {dim_name} ê°€ì´ë“œë¼ì¸ ë¬¸ì„œ í™•ì¸", "ë…ë¦½ì ì¸ ì œ3ì ê°ì‚¬ ìˆ˜í–‰"] if self.is_korean() else [f"Published {dim_name} guidelines", "Independent audit"]
                elif score >= 3.0:
                    risk_level = self.t('medium')
                    description = f"{dim_name} ì˜ì—­ì—ì„œ ê¸°ë³¸ì ì¸ ìš”êµ¬ì‚¬í•­ì€ ì¶©ì¡±í•˜ë‚˜ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤." if self.is_korean() else f"Meets basic requirements in {dim_name} but needs improvement."
                    risks = [f"{dim_name} ê´€ë ¨ ì¼ë¶€ ì •ì±… ë¯¸í¡"] if self.is_korean() else [f"Some {dim_name} policies inadequate"]
                    strengths = ["ê¸°ë³¸ì ì¸ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±"] if self.is_korean() else ["Meets basic requirements"]
                    evidence = [f"ê¸°ë³¸ì ì¸ {dim_name} ì •ì±… ì¡´ì¬"] if self.is_korean() else [f"Basic {dim_name} policy exists"]
                else:
                    risk_level = self.t('high')
                    description = f"{dim_name} ì˜ì—­ì—ì„œ ì¤‘ëŒ€í•œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤." if self.is_korean() else f"Needs significant improvement in {dim_name}."
                    risks = [f"{dim_name} ì •ì±… ë¶€ì¬ ë˜ëŠ” ë¶ˆëª…í™•", "ê°€ì´ë“œë¼ì¸ ë¯¸ì¤€ìˆ˜"] if self.is_korean() else [f"{dim_name} policy absent or unclear", "Non-compliance"]
                    strengths = ["ê°œì„  ê°€ëŠ¥ì„± ì¡´ì¬"] if self.is_korean() else ["Room for improvement"]
                    evidence = ["ëª…í™•í•œ ì •ì±… ë¬¸ì„œ ë¯¸ë°œê²¬"] if self.is_korean() else ["No clear policy found"]
                
                guideline_compliance = {}
                for guideline in ["EU AI Act", "UNESCO AI Ethics", "OECD AI Principles"]:
                    req = guideline_requirements[guideline][dim_key]
                    if score >= 4.0:
                        status = "ì¤€ìˆ˜" if self.is_korean() else "Compliant"
                        gap = "ì—†ìŒ" if self.is_korean() else "None"
                        evidence_text = f"{guideline}ì˜ ìš”êµ¬ì‚¬í•­ {status}" if self.is_korean() else f"{guideline} requirements {status}"
                    elif score >= 3.0:
                        status = "ë¶€ë¶„ì¤€ìˆ˜" if self.is_korean() else "Partial compliance"
                        gap_msg = "í•­ëª©ì˜ ì™„ì „í•œ ì´í–‰ í•„ìš”" if self.is_korean() else "Full implementation needed"
                        gap = f"'{req}' {gap_msg}"
                        evidence_text = f"{guideline}ì˜ ìš”êµ¬ì‚¬í•­ {status}" if self.is_korean() else f"{guideline} requirements {status}"
                    else:
                        status = "ë¯¸ì¤€ìˆ˜" if self.is_korean() else "Non-compliant"
                        gap_msg = "í•­ëª©ì˜ ì¦‰ê°ì ì¸ ê°œì„  í•„ìš”" if self.is_korean() else "Immediate improvement needed"
                        gap = f"'{req}' {gap_msg}"
                        evidence_text = f"{guideline}ì˜ ìš”êµ¬ì‚¬í•­ {status}" if self.is_korean() else f"{guideline} requirements {status}"
                    
                    guideline_compliance[guideline] = {
                        "status": status,
                        "requirement": req,
                        "evidence": evidence_text,
                        "gap": gap
                    }
                
                scores[dim_key] = score
                dimension_details[dim_key] = {
                    'score': score,
                    'risk_level': risk_level,
                    'description': description,
                    'evidence': evidence,
                    'guideline_compliance': guideline_compliance,
                    'reasoning': f"ì ìˆ˜ {score}ëŠ” ì •ì±… ë¬¸ì„œ ë¶„ì„, ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜ ì—¬ë¶€ ë“±ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•œ ê²°ê³¼ì…ë‹ˆë‹¤." if self.is_korean() else f"Score {score} is based on comprehensive evaluation of policy analysis and guideline compliance.",
                    'risks_identified': risks,
                    'strengths': strengths
                }
            
            overall_score = round(sum(scores.values()) / len(scores), 1)
            
            sample_data['risk_assessments'][svc] = {
                'overall_score': overall_score,
                'overall_risk_level': self.t('low') if overall_score >= 4 else self.t('medium') if overall_score >= 3 else self.t('high'),
                **dimension_details
            }
            
            # ê°œì„ ì•ˆ ìƒì„±
            improvements = []
            for dim_key, score in scores.items():
                if score < 4.5:
                    dim_name = self.get_dimension_name(dim_key)
                    if score < 3.0:
                        priority = self.t('priority_high')
                    elif score < 4.0:
                        priority = self.t('priority_medium')
                    else:
                        priority = self.t('priority_low')
                    
                    improvements.append({
                        'dimension': dim_name,
                        'priority': priority,
                        'current_score': score,
                        'target_score': min(5.0, score + 1.0),
                        'current_issues': dimension_details[dim_key]['risks_identified'],
                        'improvements': [{
                            'title': f'{dim_name} ê°•í™” í”„ë¡œê·¸ë¨' if self.is_korean() else f'{dim_name} Enhancement Program',
                            'description': f'{dim_name}ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ì²´ê³„ì ì¸ í”„ë¡œê·¸ë¨ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.' if self.is_korean() else f'Build systematic program to improve {dim_name}.',
                            'implementation_steps': [
                                '1ë‹¨ê³„: í˜„í™© ë¶„ì„ ë° ëª©í‘œ ì„¤ì •' if self.is_korean() else 'Step 1: Analyze current state and set goals',
                                '2ë‹¨ê³„: ê°œì„  ë°©ì•ˆ ìˆ˜ë¦½' if self.is_korean() else 'Step 2: Develop improvement plan',
                                '3ë‹¨ê³„: ì‹¤í–‰ ë° ëª¨ë‹ˆí„°ë§' if self.is_korean() else 'Step 3: Execute and monitor',
                                '4ë‹¨ê³„: í‰ê°€ ë° ê°œì„ ' if self.is_korean() else 'Step 4: Evaluate and improve'
                            ],
                            'expected_impact': f'{dim_name} 30% í–¥ìƒ' if self.is_korean() else f'30% improvement in {dim_name}',
                            'success_metrics': ['ê°œì„  ì™„ë£Œìœ¨', 'ë§Œì¡±ë„ ì ìˆ˜'] if self.is_korean() else ['Completion rate', 'Satisfaction score'],
                            'timeline': '3-6ê°œì›”' if self.is_korean() else '3-6 months',
                            'resources_needed': 'ì „ë¬¸ê°€ 2-3ëª…' if self.is_korean() else '2-3 experts',
                            'guideline_reference': 'EU AI Act, UNESCO AI Ethics'
                        }]
                    })
            
            sample_data['improvement_suggestions'][svc] = improvements
        
        return sample_data
    
    def generate_detailed_report(self, services: List[str], data: Dict) -> str:
        """ìƒì„¸ ë³´ê³ ì„œ ìƒì„±"""
        if self.is_korean():
            report = f"""# AI ìœ¤ë¦¬ì„± ë¦¬ìŠ¤í¬ ì§„ë‹¨ ë³´ê³ ì„œ

**ìƒì„±ì¼ì‹œ**: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}  
**ë¶„ì„ ëŒ€ìƒ**: {', '.join(services)}  
**í‰ê°€ ê¸°ì¤€**: EU AI Act, UNESCO AI Ethics, OECD AI Principles

---

## 1. ê°œìš”

ë³¸ ë³´ê³ ì„œëŠ” {len(services)}ê°œ AI ì„œë¹„ìŠ¤ì˜ ìœ¤ë¦¬ì  ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•œ ê²°ê³¼ì…ë‹ˆë‹¤.

### í‰ê°€ ëŒ€ìƒ ì„œë¹„ìŠ¤
"""
        else:
            report = f"""# AI Ethics Risk Assessment Report

**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**Services Analyzed**: {', '.join(services)}  
**Evaluation Criteria**: EU AI Act, UNESCO AI Ethics, OECD AI Principles

---

## 1. Overview

This report presents the evaluation results of ethical risks for {len(services)} AI service(s).

### Services Evaluated
"""
        
        for svc in services:
            overall = data['risk_assessments'][svc]['overall_score']
            score_text = "ì ìˆ˜" if self.is_korean() else "score"
            report += f"- **{svc}**: {self.t('overall_score')} {overall}/5{score_text}\n"
        
        report += "\n---\n\n"
        report += "## 2. " + ("ì„œë¹„ìŠ¤ë³„ ìƒì„¸ ë¶„ì„" if self.is_korean() else "Detailed Analysis by Service") + "\n\n"
        
        for svc in services:
            assessment = data['risk_assessments'][svc]
            if self.is_korean():
                report += f"""### {svc}

#### ì¢…í•© í‰ê°€
- **ì¢…í•© ì ìˆ˜**: {assessment['overall_score']}/5
- **ë¦¬ìŠ¤í¬ ìˆ˜ì¤€**: {assessment['overall_risk_level']}

#### ì°¨ì›ë³„ í‰ê°€
"""
            else:
                report += f"""### {svc}

#### Overall Assessment
- **Overall Score**: {assessment['overall_score']}/5
- **Risk Level**: {assessment['overall_risk_level']}

#### Dimension Evaluation
"""
            
            for dim_key in self.dimensions.keys():
                dim_name = self.get_dimension_name(dim_key)
                dim_data = assessment[dim_key]
                report += f"\n##### {dim_name}\n"
                report += f"- **{self.t('score')}**: {dim_data['score']}/5\n"
                report += f"- **{self.t('risk')}**: {dim_data['risk_level']}\n"
                report += f"- {dim_data['description']}\n\n"
            
            report += "\n---\n"
        
        if self.is_korean():
            report += f"""
## 3. ì¢…í•© ê¶Œê³ ì‚¬í•­

### ë‹¨ê¸° ì¡°ì¹˜ (1-3ê°œì›”)
1. AI ìœ¤ë¦¬ ì •ì±… ìˆ˜ë¦½ ë° ê³µê°œ
2. íˆ¬ëª…ì„± ë³´ê³ ì„œ ë°œí–‰

### ì¤‘ê¸° ì¡°ì¹˜ (3-6ê°œì›”)
1. í¸í–¥ì„± í…ŒìŠ¤íŠ¸ í”„ë¡œê·¸ë¨ êµ¬ì¶•
2. AI ê±°ë²„ë„ŒìŠ¤ ì²´ê³„ êµ¬ì¶•

### ì¥ê¸° ì¡°ì¹˜ (6ê°œì›” ì´ìƒ)
1. ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•
2. ì™¸ë¶€ ê°ì‚¬ ì²´ê³„ í™•ë¦½

---

**ë³´ê³ ì„œ ìƒì„±**: AI ìœ¤ë¦¬ì„± ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì‹œìŠ¤í…œ  
**ìƒì„±ì¼**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        else:
            report += f"""
## 3. Overall Recommendations

### Short-term Actions (1-3 months)
1. Establish and publish AI ethics policy
2. Issue transparency report

### Mid-term Actions (3-6 months)
1. Build bias testing program
2. Establish AI governance framework

### Long-term Actions (6+ months)
1. Build continuous monitoring system
2. Establish external audit framework

---

**Report Generated by**: AI Ethics Risk Assessment System  
**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        return report
    
    def generate_comparison_text(self, services: List[str]) -> str:
        """ë¹„êµ ë¶„ì„ í…ìŠ¤íŠ¸"""
        if len(services) < 2:
            return ""
        if self.is_korean():
            return f"ë¶„ì„ ëŒ€ìƒ {len(services)}ê°œ ì„œë¹„ìŠ¤ì˜ ìœ¤ë¦¬ ìˆ˜ì¤€ì„ ë¹„êµí•œ ê²°ê³¼, ê° ì„œë¹„ìŠ¤ë§ˆë‹¤ ê°•ì ê³¼ ê°œì„  ì˜ì—­ì´ ë‹¤ë¥´ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤."
        else:
            return f"Comparison of {len(services)} services shows different strengths and improvement areas for each service."
    
    def render_results_page(self):
        """ê²°ê³¼ í˜ì´ì§€"""
        results = st.session_state.results
        
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            self.t('tab_overview'), 
            self.t('tab_detailed'), 
            self.t('tab_improvement'), 
            self.t('tab_comparison'),
            self.t('tab_report')
        ])
        
        with tab1:
            self.render_overview_tab(results)
        with tab2:
            self.render_detailed_assessment_tab(results)
        with tab3:
            self.render_improvement_tab(results)
        with tab4:
            self.render_comparison_tab(results)
        with tab5:
            self.render_report_tab(results)
        
        # í•˜ë‹¨ ì•¡ì…˜ ë²„íŠ¼
        st.markdown("---")
        col1, col2, col3 = st.columns([1,1,1])
        with col1:
            if st.button(self.t('new_analysis')):
                st.session_state.analysis_done = False
                st.session_state.results = None
                st.rerun()
        with col2:
            if st.button(self.t('save_results')):
                self.save_report(results)
        with col3:
            report_md = results.get('report', '')
            st.download_button(
                self.t('download_report'),
                report_md,
                file_name=f"ethics_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                mime="text/markdown"
            )
    
    def render_overview_tab(self, results: Dict):
        """ì¢…í•© ëŒ€ì‹œë³´ë“œ"""
        st.header(f"ğŸ“Š {self.t('tab_overview')}")
        
        data = results['detailed_data']
        services = results['services']
        
        # KPI ë©”íŠ¸ë¦­
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown(f'<div class="metric-card"><h3>{self.t("analyzed_services")}</h3><h1>{len(services)}</h1></div>', 
                       unsafe_allow_html=True)
        
        with col2:
            avg_score = sum([svc['overall_score'] for svc in data['risk_assessments'].values()]) / len(services)
            color_class = "risk-low" if avg_score >= 4 else "risk-medium"
            st.markdown(f'<div class="metric-card {color_class}"><h3>{self.t("avg_score")}</h3><h1>{avg_score:.1f}/5</h1></div>', 
                       unsafe_allow_html=True)
        
        with col3:
            risk_level = self.t('low') if avg_score >= 4 else self.t('medium')
            color_class = "risk-low" if avg_score >= 4 else "risk-medium"
            st.markdown(f'<div class="metric-card {color_class}"><h3>{self.t("overall_risk")}</h3><h1>{risk_level}</h1></div>', 
                       unsafe_allow_html=True)
        
        with col4:
            improvement_count = sum([len(v) for v in data['improvement_suggestions'].values()])
            unit = "ê°œ" if self.is_korean() else ""
            st.markdown(f'<div class="metric-card"><h3>{self.t("improvements")}</h3><h1>{improvement_count}{unit}</h1></div>', 
                       unsafe_allow_html=True)
        
        st.markdown("---")
        
        # ë ˆì´ë” ì°¨íŠ¸ì™€ ë°” ì°¨íŠ¸
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader(f"ğŸ“¡ {self.t('dimension_evaluation')}")
            fig = go.Figure()
            
            for service in services:
                scores = data['risk_assessments'][service]
                values = [scores[dim]['score'] for dim in self.dimensions.keys()]
                
                fig.add_trace(go.Scatterpolar(
                    r=values,
                    theta=[self.get_dimension_name(dim) for dim in self.dimensions.keys()],
                    fill='toself',
                    name=service
                ))
            
            fig.update_layout(
                polar=dict(radialaxis=dict(visible=True, range=[0, 5])),
                showlegend=True,
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader(f"ğŸ“Š {self.t('score_comparison')}")
            
            df = pd.DataFrame([
                {self.t('service'): svc, self.t('overall_score'): data['risk_assessments'][svc]['overall_score']}
                for svc in services
            ])
            
            fig = px.bar(df, x=self.t('service'), y=self.t('overall_score'), 
                        color=self.t('overall_score'),
                        color_continuous_scale=['#f5576c', '#fcb69f', '#a8edea'],
                        range_color=[0, 5])
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
    
    def render_detailed_assessment_tab(self, results: Dict):
        """ìƒì„¸ í‰ê°€ íƒ­"""
        st.header(f"ğŸ“ˆ {self.t('detailed_evaluation')}")
        
        data = results['detailed_data']
        services = results['services']
        
        selected_service = st.selectbox(self.t('select_service'), services)
        
        if selected_service:
            assessment = data['risk_assessments'][selected_service]
            
            st.markdown(f"### {selected_service} {self.t('detailed_evaluation')}")
            
            col1, col2 = st.columns([1, 2])
            with col1:
                score = assessment['overall_score']
                color = "ğŸŸ¢" if score >= 4 else "ğŸŸ¡" if score >= 3 else "ğŸ”´"
                st.markdown(f"## {color} {score}/5")
                st.markdown(f"**{self.t('risk')}**: {assessment['overall_risk_level']}")
            
            with col2:
                st.markdown(f"#### {self.t('overall_assessment')}")
                if score >= 4:
                    msg = f"{selected_service} {self.t('excellent')}"
                    st.success(msg)
                elif score >= 3:
                    msg = f"{selected_service} {self.t('good')}"
                    st.warning(msg)
                else:
                    msg = f"{selected_service} {self.t('needs_improvement')}"
                    st.error(msg)
            
            st.markdown("---")
            st.subheader(f"ğŸ“‹ {self.t('dimension_details')}")
            
            for dim_key in self.dimensions.keys():
                dim_name = self.get_dimension_name(dim_key)
                dim_data = assessment[dim_key]
                
                with st.expander(f"{'ğŸŸ¢' if dim_data['score'] >= 4 else 'ğŸŸ¡' if dim_data['score'] >= 3 else 'ğŸ”´'} {dim_name} - {dim_data['score']}/5", expanded=False):
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric(self.t('score'), f"{dim_data['score']}/5")
                    with col2:
                        st.metric(self.t('risk'), dim_data['risk_level'])
                    with col3:
                        if isinstance(dim_data.get('guideline_compliance'), dict):
                            compliance_count = sum(
                                1 for c in dim_data['guideline_compliance'].values() 
                                if isinstance(c, dict) and ('ì¤€ìˆ˜' in c.get('status', '') or 'Compliant' in c.get('status', ''))
                            )
                            st.metric(self.t('guideline_compliance'), f"{compliance_count}/3")
                        else:
                            st.metric(self.t('guideline_compliance'), "N/A")
                    
                    st.markdown(f"#### ğŸ“ {self.t('evaluation_desc')}")
                    st.markdown(f'<div class="detail-card">{dim_data["description"]}</div>', unsafe_allow_html=True)
                    
                    st.markdown(f"#### ğŸ“Œ {self.t('key_evidence')}")
                    if isinstance(dim_data.get('evidence'), list):
                        for evidence in dim_data['evidence']:
                            st.markdown(f'<div class="evidence-item">âœ“ {evidence}</div>', unsafe_allow_html=True)
                    else:
                        st.info(self.t('no_evidence'))
                    
                    st.markdown(f"#### âš–ï¸ {self.t('guideline_compliance')}")
                    if isinstance(dim_data.get('guideline_compliance'), dict):
                        for guideline, compliance in dim_data['guideline_compliance'].items():
                            if isinstance(compliance, dict):
                                status = compliance.get('status', 'N/A')
                                if 'ì¤€ìˆ˜' in status or 'Compliant' in status:
                                    status_emoji = "âœ…"
                                elif 'ë¶€ë¶„' in status or 'Partial' in status:
                                    status_emoji = "âš ï¸"
                                else:
                                    status_emoji = "âŒ"
                                st.markdown(f"**{status_emoji} {guideline}**: {status}")
                            else:
                                st.markdown(f"**{guideline}**: {compliance}")
                    else:
                        st.info(self.t('no_evidence'))
                    
                    if dim_data.get('risks_identified'):
                        st.markdown(f"#### âš ï¸ {self.t('identified_risks')}")
                        if isinstance(dim_data['risks_identified'], list):
                            for risk in dim_data['risks_identified']:
                                st.markdown(f'<div class="risk-item">âš ï¸ {risk}</div>', unsafe_allow_html=True)
                    
                    if dim_data.get('strengths'):
                        st.markdown(f"#### âœ… {self.t('strengths')}")
                        if isinstance(dim_data['strengths'], list):
                            for strength in dim_data['strengths']:
                                st.markdown(f'<div class="strength-item">âœ“ {strength}</div>', unsafe_allow_html=True)
    
    def render_improvement_tab(self, results: Dict):
        """ê°œì„  ê¶Œê³ ì•ˆ íƒ­"""
        st.header(f"ğŸ’¡ {self.t('improvement_recommendations')}")
        
        data = results['detailed_data']
        services = results['services']
        
        selected_service = st.selectbox(self.t('select_service'), services, key="improvement_select")
        
        if selected_service:
            improvements = data['improvement_suggestions'][selected_service]
            
            st.markdown(f"### {selected_service} {self.t('improvement_recommendations')}")
            
            if not improvements:
                st.success(self.t('all_excellent'))
            else:
                priority_options = [self.t('all'), self.t('priority_high'), self.t('priority_medium'), self.t('priority_low')]
                priority_filter = st.radio(self.t('priority_filter'), priority_options, horizontal=True)
                
                filtered_improvements = improvements if priority_filter == self.t('all') else [
                    imp for imp in improvements if imp['priority'] == priority_filter
                ]
                
                for idx, imp in enumerate(filtered_improvements, 1):
                    if imp['priority'] == self.t('priority_high'):
                        priority_color = "ğŸ”´"
                    elif imp['priority'] == self.t('priority_medium'):
                        priority_color = "ğŸŸ¡"
                    else:
                        priority_color = "ğŸŸ¢"
                    
                    priority_label = "ìš°ì„ ìˆœìœ„" if self.is_korean() else "Priority"
                    with st.expander(f"{priority_color} {imp['dimension']} ({priority_label}: {imp['priority']})", expanded=True):
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric(self.t('current_score'), f"{imp['current_score']}/5")
                        with col2:
                            st.metric(self.t('target_score'), f"{imp['target_score']}/5")
                        with col3:
                            improvement = imp['target_score'] - imp['current_score']
                            st.metric(self.t('improvement_goal'), f"+{improvement:.1f}")
                        
                        st.markdown(f"#### âš ï¸ {self.t('current_issues')}")
                        for issue in imp['current_issues']:
                            st.markdown(f'<div class="risk-item">â€¢ {issue}</div>', unsafe_allow_html=True)
                        
                        st.markdown("---")
                        st.markdown(f"#### ğŸ¯ {self.t('recommended_actions')}")
                        
                        for imp_idx, action in enumerate(imp['improvements'], 1):
                            st.markdown(f"##### {imp_idx}. {action['title']}")
                            st.write(action['description'])
                            
                            col1, col2 = st.columns([3, 2])
                            
                            with col1:
                                st.markdown(f"**ğŸ“‹ {self.t('implementation_steps')}**")
                                for step in action['implementation_steps']:
                                    st.markdown(f"- {step}")
                            
                            with col2:
                                st.markdown(f"**ğŸ“Š {self.t('expected_impact')}**")
                                st.info(action['expected_impact'])
                                st.markdown(f"**â±ï¸ {self.t('timeline')}**")
                                st.code(action['timeline'])
    
    def render_comparison_tab(self, results: Dict):
        """ë¹„êµ ë¶„ì„ íƒ­"""
        st.header(f"ğŸ” {self.t('comparison_analysis')}")
        
        data = results['detailed_data']
        services = results['services']
        
        if len(services) < 2:
            st.info(self.t('comparison_note'))
            return
        
        if data.get('comparison_analysis'):
            st.markdown(data['comparison_analysis'])
        
        st.markdown("---")
        st.subheader(f"ğŸ“Š {self.t('dimension_comparison')}")
        
        comparison_data = []
        for dim_key in self.dimensions.keys():
            dim_name = self.get_dimension_name(dim_key)
            row = {self.t('dimension'): dim_name}
            for svc in services:
                row[svc] = data['risk_assessments'][svc][dim_key]['score']
            comparison_data.append(row)
        
        df_comparison = pd.DataFrame(comparison_data)
        
        # ìŠ¤íƒ€ì¼ë§ëœ í…Œì´ë¸”
        def color_score(val):
            if isinstance(val, (int, float)):
                if val >= 4:
                    return 'background-color: #c8e6c9; color: #1b5e20'
                elif val >= 3:
                    return 'background-color: #fff9c4; color: #f57f17'
                else:
                    return 'background-color: #ffcdd2; color: #b71c1c'
            return ''
        
        try:
            styled_df = df_comparison.style.map(color_score, subset=services)
        except AttributeError:
            styled_df = df_comparison.style.applymap(color_score, subset=services)
        
        st.dataframe(styled_df, use_container_width=True)
        
        # íˆíŠ¸ë§µ
        st.markdown("---")
        st.subheader(f"ğŸŒ¡ï¸ {self.t('score_heatmap')}")
        
        heatmap_data = []
        for svc in services:
            row = [data['risk_assessments'][svc][dim]['score'] for dim in self.dimensions.keys()]
            heatmap_data.append(row)
        
        score_label = "ì ìˆ˜" if self.is_korean() else "Score"
        fig = go.Figure(data=go.Heatmap(
            z=heatmap_data,
            x=[self.get_dimension_name(dim) for dim in self.dimensions.keys()],
            y=services,
            colorscale='RdYlGn',
            zmid=3,
            zmin=0,
            zmax=5,
            text=[[f"{val:.1f}" for val in row] for row in heatmap_data],
            texttemplate='%{text}',
            textfont={"size": 14},
            colorbar=dict(title=score_label)
        ))
        
        dim_label = "í‰ê°€ ì°¨ì›" if self.is_korean() else "Dimensions"
        svc_label = "ì„œë¹„ìŠ¤" if self.is_korean() else "Services"
        fig.update_layout(
            height=300 + len(services) * 50,
            xaxis_title=dim_label,
            yaxis_title=svc_label
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def render_report_tab(self, results: Dict):
        """ìµœì¢… ë³´ê³ ì„œ íƒ­"""
        st.header(f"ğŸ“„ {self.t('final_report')}")
        
        report_md = results.get('report', '')
        st.markdown(report_md)
        
        st.markdown("---")
        st.subheader(f"ğŸ’¾ {self.t('report_download')}")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.download_button(
                "ğŸ“¥ Markdown",
                report_md,
                file_name=f"ethics_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                mime="text/markdown"
            )
        
        with col2:
            json_data = json.dumps(results['detailed_data'], ensure_ascii=False, indent=2)
            st.download_button(
                "ğŸ“¥ JSON",
                json_data,
                file_name=f"ethics_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
        
        with col3:
            services = results['services']
            data = results['detailed_data']
            
            csv_data = []
            for svc in services:
                row = {self.t('service'): svc}
                for dim_key in self.dimensions.keys():
                    dim_name = self.get_dimension_name(dim_key)
                    row[dim_name] = data['risk_assessments'][svc][dim_key]['score']
                row[self.t('overall_score')] = data['risk_assessments'][svc]['overall_score']
                csv_data.append(row)
            
            df_csv = pd.DataFrame(csv_data)
            csv_string = df_csv.to_csv(index=False, encoding='utf-8-sig')
            
            st.download_button(
                "ğŸ“¥ CSV",
                csv_string,
                file_name=f"ethics_scores_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
    
    def save_report(self, results: Dict):
        """ë³´ê³ ì„œ ì €ì¥"""
        try:
            save_dir = "saved_reports"
            os.makedirs(save_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            report_path = os.path.join(save_dir, f"report_{timestamp}.md")
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(results['report'])
            
            data_path = os.path.join(save_dir, f"data_{timestamp}.json")
            with open(data_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            success_msg = f"âœ… {self.t('report_saved')}!\n- {report_path}\n- {data_path}"
            st.success(success_msg)
            
        except Exception as e:
            error_msg = f"âŒ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}" if self.is_korean() else f"âŒ Error saving: {e}"
            st.error(error_msg)
    
    def load_previous_report(self):
        """ì´ì „ ë³´ê³ ì„œ ë¶ˆëŸ¬ì˜¤ê¸°"""
        save_dir = "saved_reports"
        
        if not os.path.exists(save_dir):
            st.warning(self.t('no_saved_reports'))
            return
        
        json_files = [f for f in os.listdir(save_dir) if f.endswith('.json')]
        
        if not json_files:
            st.warning(self.t('no_saved_reports'))
            return
        
        json_files.sort(reverse=True)
        
        selected_file = st.selectbox(self.t('select_report'), json_files)
        
        if st.button(self.t('load')):
            try:
                file_path = os.path.join(save_dir, selected_file)
                with open(file_path, 'r', encoding='utf-8') as f:
                    loaded_results = json.load(f)
                
                st.session_state.results = loaded_results
                st.session_state.analysis_done = True
                st.success(f"âœ… {self.t('report_loaded')}!")
                st.rerun()
                
            except Exception as e:
                error_msg = f"âŒ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}" if self.is_korean() else f"âŒ Load failed: {e}"
                st.error(error_msg)


# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    dashboard = EthicsDashboard()
    dashboard.run()
import os
from dotenv import load_dotenv
from utils.graph import EthicsAssessmentGraph
from utils.helpers import (
    validate_service_names,
    validate_guidelines,
    save_report,
    save_json,
    get_timestamp,
    print_section_header,
    print_section_footer
)
from config.settings import MAX_SERVICES, SUPPORTED_GUIDELINES

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv(override=True)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print_section_header("AI ìœ¤ë¦¬ì„± ë¦¬ìŠ¤í¬ ì§„ë‹¨ ì‹œìŠ¤í…œ")
    
    # ========== 1. ì‚¬ìš©ì ì…ë ¥ ==========
    print("ğŸ“‹ ë¶„ì„ ì„¤ì •ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\n")
    
    # ë¶„ì„ ëŒ€ìƒ ì„œë¹„ìŠ¤ ì…ë ¥
    print(f"ë¶„ì„í•  AI ì„œë¹„ìŠ¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ìµœëŒ€ {MAX_SERVICES}ê°œ, ì‰¼í‘œë¡œ êµ¬ë¶„):")
    print("ì˜ˆì‹œ: ChatGPT, Midjourney, GitHub Copilot")
    services_input = input(">>> ").strip()
    
    service_names = [s.strip() for s in services_input.split(",") if s.strip()]
    
    # ìœ íš¨ì„± ê²€ì‚¬
    if not validate_service_names(service_names, MAX_SERVICES):
        return
    
    print(f"\nâœ… ë¶„ì„ ëŒ€ìƒ: {', '.join(service_names)}")
    
    # ê°€ì´ë“œë¼ì¸ ì„ íƒ
    print(f"\nì‚¬ìš©í•  ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸ì„ ì„ íƒí•˜ì„¸ìš”:")
    print(f"ì§€ì› ê°€ì´ë“œë¼ì¸: {', '.join(SUPPORTED_GUIDELINES)}")
    print("ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥ (ì‰¼í‘œë¡œ êµ¬ë¶„), ì—”í„° ì…ë ¥ ì‹œ ëª¨ë‘ ì„ íƒ")
    guidelines_input = input(">>> ").strip()
    
    if not guidelines_input:
        guidelines = SUPPORTED_GUIDELINES
    else:
        guidelines = [g.strip() for g in guidelines_input.split(",") if g.strip()]
    
    # ìœ íš¨ì„± ê²€ì‚¬
    if not validate_guidelines(guidelines, SUPPORTED_GUIDELINES):
        return
    
    print(f"\nâœ… í‰ê°€ ê¸°ì¤€: {', '.join(guidelines)}")
    
    print_section_footer()
    
    # ========== 2. ì´ˆê¸° State êµ¬ì„± ==========
    initial_state = {
        "service_names": service_names,
        "guidelines": guidelines,
        "service_analysis": {},
        "risk_assessment": {},
        "improvement_suggestions": {},
        "comparison_analysis": "",
        "final_report": None,
        "references": [],
        "messages": [],
        "current_service": None
    }
    
    # ========== 3. ê·¸ë˜í”„ ì‹¤í–‰ ==========
    print_section_header("ë¶„ì„ ì‹œì‘")
    
    try:
        graph = EthicsAssessmentGraph()
        
        print("ğŸ”„ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘...\n")
        result_state = graph.run(initial_state)
        
        print_section_footer()
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # ========== 4. ê²°ê³¼ ì €ì¥ ==========
    print_section_header("ê²°ê³¼ ì €ì¥")
    
    timestamp = get_timestamp()
    
    # ìµœì¢… ë³´ê³ ì„œ ì €ì¥
    if result_state.get("final_report"):
        report_filename = f"ethics_report_{timestamp}.md"
        report_path = save_report(
            content=result_state["final_report"],
            filename=report_filename
        )
        print(f"ğŸ“„ ë³´ê³ ì„œ: {report_path}")
    
    # ì „ì²´ ê²°ê³¼ JSON ì €ì¥
    result_data = {
        "timestamp": timestamp,
        "services": result_state["service_names"],
        "guidelines": result_state["guidelines"],
        "service_analysis": result_state.get("service_analysis", {}),
        "risk_assessment": result_state.get("risk_assessment", {}),
        "improvement_suggestions": result_state.get("improvement_suggestions", {}),
        "comparison_analysis": result_state.get("comparison_analysis", "")
    }
    
    json_filename = f"outputs/logs/result_{timestamp}.json"
    save_json(result_data, json_filename)
    print(f"ğŸ’¾ ìƒì„¸ ê²°ê³¼: {json_filename}")
    
    print_section_footer()
    
    # ========== 5. ìš”ì•½ ì¶œë ¥ ==========
    print_section_header("ë¶„ì„ ìš”ì•½")
    
    print("ğŸ“Š í‰ê°€ ê²°ê³¼ ìš”ì•½:\n")
    
    for service_name in result_state["service_names"]:
        assessment = result_state["risk_assessment"].get(service_name, {})
        overall_score = assessment.get("overall_score", 0)
        
        print(f"ğŸ”¹ {service_name}")
        print(f"   ì¢…í•© ì ìˆ˜: {overall_score:.2f}/5.0")
        
        # ê° ì°¨ì›ë³„ ì ìˆ˜
        dimensions = ["bias", "privacy", "transparency", "accountability"]
        for dim in dimensions:
            if dim in assessment:
                score = assessment[dim].get("score", 0)
                risk_level = assessment[dim].get("risk_level", "ì•Œ ìˆ˜ ì—†ìŒ")
                
                dim_names = {
                    "bias": "í¸í–¥ì„±",
                    "privacy": "í”„ë¼ì´ë²„ì‹œ",
                    "transparency": "íˆ¬ëª…ì„±",
                    "accountability": "ì±…ì„ì„±"
                }
                
                print(f"   - {dim_names[dim]}: {score}/5 ({risk_level})")
        
        print()
    
    print_section_footer()
    
    print("âœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n")
    print(f"ğŸ“ ë³´ê³ ì„œ ìœ„ì¹˜: outputs/reports/")
    print(f"ğŸ“ ìƒì„¸ ë¡œê·¸: outputs/logs/\n")

if __name__ == "__main__":
    main()
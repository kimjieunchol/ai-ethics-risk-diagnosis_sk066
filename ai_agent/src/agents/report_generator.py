from langchain_openai import ChatOpenAI
from src.graph.state import AIEthicsState
from src.prompts.report_prompt import get_report_prompt
from datetime import datetime
from pathlib import Path
import os


class ReportGeneratorAgent:
    """ë³´ê³ ì„œ ìƒì„± ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.3,
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
    
    def prepare_references(self, state: AIEthicsState) -> list:
        """ì°¸ê³  ë¬¸í—Œ ì •ë¦¬"""
        guidelines = state.get('retrieved_guidelines', [])
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
        references = {}
        for guideline in guidelines:
            source = guideline.get('source', 'ì¶œì²˜ ë¶ˆëª…')
            url = guideline.get('url', '')
            if source not in references:
                references[source] = url
        
        return [
            f"- {source}: {url}" if url else f"- {source}"
            for source, url in references.items()
        ]
    
    def format_risk_section(self, risk_data: dict, category_name: str) -> str:
        """ë¦¬ìŠ¤í¬ ì„¹ì…˜ í¬ë§·íŒ…"""
        if not risk_data:
            return f"{category_name} í‰ê°€ ê²°ê³¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        section = f"**ë¦¬ìŠ¤í¬ ì ìˆ˜:** {risk_data.get('ë¦¬ìŠ¤í¬_ì ìˆ˜', 'N/A')}/100\n\n"
        section += f"**ë¦¬ìŠ¤í¬ ìˆ˜ì¤€:** {risk_data.get('ë¦¬ìŠ¤í¬_ìˆ˜ì¤€', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n\n"
        
        findings = risk_data.get('ë°œê²¬ì‚¬í•­', [])
        if findings:
            section += "**ì£¼ìš” ë°œê²¬ì‚¬í•­:**\n"
            for finding in findings[:3]:  # ìƒìœ„ 3ê°œ
                if isinstance(finding, dict):
                    section += f"- {finding.get('ì´ìŠˆ', 'N/A')}\n"
                    section += f"  - ì‹¬ê°ë„: {finding.get('ì‹¬ê°ë„', 'N/A')}\n"
                    section += f"  - ìž ìž¬ì  í”¼í•´: {finding.get('ìž ìž¬ì _í”¼í•´', 'N/A')}\n"
        
        return section
    
    def generate_report(self, state: AIEthicsState) -> AIEthicsState:
        """ìµœì¢… ë³´ê³ ì„œ ìƒì„±"""
        print("\nðŸ“ ìµœì¢… ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        # ì°¸ê³  ë¬¸í—Œ ì¤€ë¹„
        references = self.prepare_references(state)
        state['references'] = references
        
        # ë¦¬ìŠ¤í¬ ì„¹ì…˜ í¬ë§·íŒ…
        formatted_state = state.copy()
        formatted_state['íŽ¸í–¥ì„±_ë¦¬ìŠ¤í¬_í¬ë§·'] = self.format_risk_section(
            state.get('bias_risk', {}), 'íŽ¸í–¥ì„±'
        )
        formatted_state['ê°œì¸ì •ë³´_ë¦¬ìŠ¤í¬_í¬ë§·'] = self.format_risk_section(
            state.get('privacy_risk', {}), 'ê°œì¸ì •ë³´ ë³´í˜¸'
        )
        formatted_state['íˆ¬ëª…ì„±_ë¦¬ìŠ¤í¬_í¬ë§·'] = self.format_risk_section(
            state.get('transparency_risk', {}), 'íˆ¬ëª…ì„±'
        )
        formatted_state['ê³µì •ì„±_ë¦¬ìŠ¤í¬_í¬ë§·'] = self.format_risk_section(
            state.get('fairness_risk', {}), 'ê³µì •ì„±'
        )
        formatted_state['ì•ˆì „ì„±_ë¦¬ìŠ¤í¬_í¬ë§·'] = self.format_risk_section(
            state.get('safety_risk', {}), 'ì•ˆì „ì„±'
        )
        formatted_state['ì±…ìž„ì„±_ë¦¬ìŠ¤í¬_í¬ë§·'] = self.format_risk_section(
            state.get('accountability_risk', {}), 'ì±…ìž„ì„±'
        )
        
        # ë‚ ì§œ ì¶”ê°€
        formatted_state['í‰ê°€ì¼ìž'] = datetime.now().strftime('%Yë…„ %mì›” %dì¼')
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""AI ìœ¤ë¦¬ì„± ë¦¬ìŠ¤í¬ ì§„ë‹¨ ë³´ê³ ì„œë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ìž‘ì„±í•´ì£¼ì„¸ìš”.

ì„œë¹„ìŠ¤ëª…: {state['service_name']}
ì¢…í•© ë¦¬ìŠ¤í¬ ì ìˆ˜: {state.get('overall_risk_score', 0)}/100
ë¦¬ìŠ¤í¬ ìˆ˜ì¤€: {state.get('risk_level', 'ì•Œ ìˆ˜ ì—†ìŒ')}
í‰ê°€ ì¼ìž: {formatted_state['í‰ê°€ì¼ìž']}

ê³ ìœ„í—˜ ì˜ì—­: {', '.join(state.get('high_risk_areas', []))}

ì„œë¹„ìŠ¤ ë¶„ì„:
{state.get('service_analysis', {})}

ë¦¬ìŠ¤í¬ í‰ê°€ ê²°ê³¼:

íŽ¸í–¥ì„± ë¦¬ìŠ¤í¬:
{formatted_state['íŽ¸í–¥ì„±_ë¦¬ìŠ¤í¬_í¬ë§·']}

ê°œì¸ì •ë³´ ë³´í˜¸ ë¦¬ìŠ¤í¬:
{formatted_state['ê°œì¸ì •ë³´_ë¦¬ìŠ¤í¬_í¬ë§·']}

íˆ¬ëª…ì„± ë¦¬ìŠ¤í¬:
{formatted_state['íˆ¬ëª…ì„±_ë¦¬ìŠ¤í¬_í¬ë§·']}

ê³µì •ì„± ë¦¬ìŠ¤í¬:
{formatted_state['ê³µì •ì„±_ë¦¬ìŠ¤í¬_í¬ë§·']}

ì•ˆì „ì„± ë¦¬ìŠ¤í¬:
{formatted_state['ì•ˆì „ì„±_ë¦¬ìŠ¤í¬_í¬ë§·']}

ì±…ìž„ì„± ë¦¬ìŠ¤í¬:
{formatted_state['ì±…ìž„ì„±_ë¦¬ìŠ¤í¬_í¬ë§·']}

ìš°ì„  ì¡°ì¹˜ì‚¬í•­:
{chr(10).join(f"{i+1}. {action}" for i, action in enumerate(state.get('priority_actions', [])))}

ê°œì„  ë°©ì•ˆ:
{state.get('recommendations', [])}

ì°¸ê³  ë¬¸í—Œ:
{chr(10).join(references)}

ë‹¤ìŒ êµ¬ì¡°ë¡œ ì „ë¬¸ì ì´ê³  ì²´ê³„ì ì¸ ë³´ê³ ì„œë¥¼ ìž‘ì„±í•´ì£¼ì„¸ìš”:
1. ìš”ì•½ (SUMMARY)
2. ê° ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ë¦¬ìŠ¤í¬ ë¶„ì„
3. ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆ
4. ì°¸ê³  ë¬¸í—Œ ë° ë¶€ë¡

ê¹”ë”í•œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ìž‘ì„±í•˜ê³ , ì ì ˆí•œ í—¤ë”, ëª©ë¡, í‘œë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.
ëª¨ë“  ë‚´ìš©ì€ í•œêµ­ì–´ë¡œ ìž‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ ê¸°ìˆ  ë³´ê³ ì„œ ìž‘ì„±ìžìž…ë‹ˆë‹¤. ëª¨ë“  ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ìž‘ì„±í•©ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]
        
        response = self.llm.invoke(messages)
        report = response.content
        
        state['final_report'] = report
        
        # ë³´ê³ ì„œ ì €ìž¥
        self.save_report(report, state['service_name'])
        
        print("âœ“ ìµœì¢… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
        
        return state
    
    def save_report(self, report: str, service_name: str):
        """ë³´ê³ ì„œ íŒŒì¼ë¡œ ì €ìž¥"""
        output_dir = Path("outputs/reports")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{service_name.replace(' ', '_')}_{timestamp}.md"
        filepath = output_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"âœ“ ë³´ê³ ì„œ ì €ìž¥ ì™„ë£Œ: {filepath}")


def report_generator_node(state: AIEthicsState) -> AIEthicsState:
    """LangGraph ë…¸ë“œ í•¨ìˆ˜"""
    agent = ReportGeneratorAgent()
    return agent.generate_report(state)
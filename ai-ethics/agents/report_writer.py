from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from typing import Dict, List
from datetime import datetime
import json
from config.settings import LLM_MODEL, LLM_TEMPERATURE, OPENAI_API_KEY
from prompts.report_generation import REPORT_GENERATION_PROMPT, SUMMARY_PROMPT

class ReportWriter:
    """ë¦¬í¬íŠ¸ ì‘ì„± ì—ì´ì „íŠ¸ - ì§„ë‹¨ ê²°ê³¼ ë° ê¶Œê³ ì‚¬í•­ ë¦¬í¬íŠ¸ ìƒì„±"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model=LLM_MODEL,
            temperature=LLM_TEMPERATURE,
            openai_api_key=OPENAI_API_KEY
        )
    
    def generate_report(
        self,
        services: List[str],
        service_analyses: Dict[str, Dict],
        risk_assessments: Dict[str, Dict],
        improvement_suggestions: Dict[str, List[Dict]],
        comparison_analysis: str
    ) -> str:
        """ìµœì¢… ë³´ê³ ì„œ ìƒì„±"""
        
        print(f"\n{'='*60}")
        print(f"ğŸ“ ìµœì¢… ë³´ê³ ì„œ ì‘ì„±")
        print(f"{'='*60}\n")
        
        # 1. ì°¸ê³ ë¬¸í—Œ ìˆ˜ì§‘
        all_references = []
        for analysis in service_analyses.values():
            all_references.extend(analysis.get('references', []))
        
        # 2. ë©”ì¸ ë³´ê³ ì„œ ìƒì„±
        print(f"  âœï¸  ë³¸ë¬¸ ì‘ì„± ì¤‘...")
        main_report = self._generate_main_report(
            services=services,
            service_analyses=service_analyses,
            risk_assessments=risk_assessments,
            improvement_suggestions=improvement_suggestions,
            comparison_analysis=comparison_analysis,
            references=all_references
        )
        
        # 3. Executive Summary ìƒì„±
        print(f"  ğŸ“‹ Executive Summary ì‘ì„± ì¤‘...")
        summary = self._generate_summary(main_report, services, risk_assessments)
        
        # 4. ìµœì¢… ì¡°í•©
        final_report = self._assemble_final_report(
            summary=summary,
            main_report=main_report,
            services=services
        )
        
        print(f"\n  âœ… ë³´ê³ ì„œ ì‘ì„± ì™„ë£Œ!")
        print(f"     - ì´ ê¸¸ì´: {len(final_report):,} ì")
        print(f"     - ë‹¨ì–´ ìˆ˜: {len(final_report.split()):,} ê°œ")
        
        return final_report
    
    def _generate_main_report(
        self,
        services: List[str],
        service_analyses: Dict,
        risk_assessments: Dict,
        improvement_suggestions: Dict,
        comparison_analysis: str,
        references: List[Dict]
    ) -> str:
        """ë©”ì¸ ë³´ê³ ì„œ ìƒì„±"""
        
        formatted_refs = self._format_references(references)
        
        prompt = REPORT_GENERATION_PROMPT.format(
            services=", ".join(services),
            service_analyses=json.dumps(service_analyses, ensure_ascii=False, indent=2),
            risk_assessments=json.dumps(risk_assessments, ensure_ascii=False, indent=2),
            improvement_suggestions=json.dumps(improvement_suggestions, ensure_ascii=False, indent=2),
            comparison_analysis=comparison_analysis if comparison_analysis else "ë‹¨ì¼ ì„œë¹„ìŠ¤ ë¶„ì„"
        )
        
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ì „ë¬¸ ê¸°ìˆ  ë¦¬í¬íŠ¸ ì‘ì„±ìì…ë‹ˆë‹¤. ëª…í™•í•˜ê³  êµ¬ì¡°í™”ë˜ë©° ì‹¤í–‰ ê°€ëŠ¥í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”."),
            HumanMessage(content=prompt)
        ]
        
        response = self.llm.invoke(messages)
        
        # ì°¸ê³ ë¬¸í—Œ ì¶”ê°€
        return response.content + "\n\n---\n\n# ì°¸ê³  ë¬¸í—Œ\n\n" + formatted_refs
    
    def _generate_summary(
        self, 
        report_content: str,
        services: List[str],
        risk_assessments: Dict
    ) -> str:
        """Executive Summary ìƒì„±"""
        
        # ë³´ê³ ì„œê°€ ë„ˆë¬´ ê¸¸ë©´ ì¼ë¶€ë§Œ ì‚¬ìš©
        if len(report_content) > 10000:
            report_content = report_content[:10000] + "\n...(ì´í•˜ ìƒëµ)..."
        
        prompt = SUMMARY_PROMPT.format(report_content=report_content)
        
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ì „ë¬¸ ë¦¬í¬íŠ¸ ì‘ì„±ìì…ë‹ˆë‹¤. í•µì‹¬ì„ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”."),
            HumanMessage(content=prompt)
        ]
        
        response = self.llm.invoke(messages)
        
        return response.content
    
    def _assemble_final_report(
        self,
        summary: str,
        main_report: str,
        services: List[str]
    ) -> str:
        """ìµœì¢… ë³´ê³ ì„œ ì¡°í•©"""
        
        current_date = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
        
        header = f"""# AI ìœ¤ë¦¬ì„± ë¦¬ìŠ¤í¬ ì§„ë‹¨ ë³´ê³ ì„œ

**ë¶„ì„ ëŒ€ìƒ**: {", ".join(services)}  
**ì‘ì„±ì¼**: {current_date}  
**í‰ê°€ ê¸°ì¤€**: EU AI Act, UNESCO AI Ethics, OECD AI Principles

---

"""
        
        executive_summary = f"""# EXECUTIVE SUMMARY

{summary}

---

"""
        
        final_report = header + executive_summary + main_report
        
        return final_report
    
    def _format_references(self, references: List[Dict]) -> str:
        """ì°¸ê³ ë¬¸í—Œ í¬ë§·íŒ…"""
        
        if not references:
            return "ì°¸ê³  ìë£Œ ì—†ìŒ"
        
        # ì¤‘ë³µ ì œê±° (URL ê¸°ì¤€)
        unique_refs = {}
        for ref in references:
            url = ref.get('url', '')
            if url and url not in unique_refs:
                unique_refs[url] = ref
        
        # ì¶œì²˜ë³„ ë¶„ë¥˜
        web_refs = [r for r in unique_refs.values() if r.get('source') == 'web']
        
        formatted = []
        
        if web_refs:
            formatted.append("## ì›¹ ê²€ìƒ‰ ìë£Œ\n")
            for i, ref in enumerate(web_refs, 1):
                title = ref.get('title', 'ì œëª© ì—†ìŒ')
                url = ref.get('url', '')
                formatted.append(f"{i}. [{title}]({url})")
        
        return "\n".join(formatted) if formatted else "ì°¸ê³  ìë£Œ ì—†ìŒ"

